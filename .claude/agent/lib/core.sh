#!/usr/bin/env bash
#
# Claude Agent - Core Logic
#
# This is the core agent implementation. It can be run directly or via run.sh.
# When run via run.sh, AGENT_DIR and PROJECT_DIR are pre-configured.
#
# PHASES:
#   1. TRIAGE    - Validate task, check dependencies (2min)
#   2. PLAN      - Gap analysis, detailed planning (5min)
#   3. IMPLEMENT - Execute the plan, write code (30min)
#   4. TEST      - Run tests, add coverage (10min)
#   5. DOCS      - Sync documentation (5min)
#   6. REVIEW    - Code review, create follow-ups (10min)
#   7. VERIFY    - Verify task management, commit task files (3min)
#
# FEATURES:
#   - Modular phase-based execution (fresh context per phase)
#   - Phase-specific prompts and timeouts
#   - Automatic retry with exponential backoff
#   - Model fallback (opus -> sonnet on rate limits)
#   - Parallel agent support via lock files
#   - Self-healing and crash recovery
#
set -euo pipefail

# ============================================================================
# Path Configuration (supports both direct and wrapped execution)
# ============================================================================

# If AGENT_DIR is set (by run.sh), use it; otherwise derive from this script's location
if [ -z "${AGENT_DIR:-}" ]; then
  AGENT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
fi

# If PROJECT_DIR is set (by run.sh), use it; otherwise derive from AGENT_DIR
if [ -z "${PROJECT_DIR:-}" ]; then
  # Assume we're in .claude/agent/lib/, so project root is 3 levels up
  PROJECT_DIR="$(cd "$AGENT_DIR/../.." && pwd)"
fi

# Agent resources (portable - part of the agent package)
PROMPTS_DIR="${PROMPTS_DIR:-$AGENT_DIR/prompts}"
SCRIPTS_DIR="${SCRIPTS_DIR:-$AGENT_DIR/scripts}"

# Project-specific directories (not portable - stay in project's .claude/)
CLAUDE_DIR="${CLAUDE_DIR:-$PROJECT_DIR/.claude}"
TASKS_DIR="${TASKS_DIR:-$CLAUDE_DIR/tasks}"
LOGS_DIR="${LOGS_DIR:-$CLAUDE_DIR/logs/claude-loop}"
STATE_DIR="${STATE_DIR:-$CLAUDE_DIR/state}"
LOCKS_DIR="${LOCKS_DIR:-$CLAUDE_DIR/locks}"

# ============================================================================
# Configuration Defaults
# ============================================================================

NUM_TASKS="${1:-5}"
CLAUDE_MODEL="${CLAUDE_MODEL:-opus}"
AGENT_DRY_RUN="${AGENT_DRY_RUN:-0}"
AGENT_VERBOSE="${AGENT_VERBOSE:-0}"
AGENT_QUIET="${AGENT_QUIET:-0}"
AGENT_PROGRESS="${AGENT_PROGRESS:-1}"
AGENT_MAX_RETRIES="${AGENT_MAX_RETRIES:-2}"
AGENT_RETRY_DELAY="${AGENT_RETRY_DELAY:-5}"
AGENT_NO_RESUME="${AGENT_NO_RESUME:-0}"
AGENT_LOCK_TIMEOUT="${AGENT_LOCK_TIMEOUT:-10800}"
AGENT_HEARTBEAT="${AGENT_HEARTBEAT:-3600}"
AGENT_NO_FALLBACK="${AGENT_NO_FALLBACK:-0}"

# Phase skip flags (set to 1 to skip)
SKIP_TRIAGE="${SKIP_TRIAGE:-0}"
SKIP_PLAN="${SKIP_PLAN:-0}"
SKIP_IMPLEMENT="${SKIP_IMPLEMENT:-0}"
SKIP_TEST="${SKIP_TEST:-0}"
SKIP_DOCS="${SKIP_DOCS:-0}"
SKIP_REVIEW="${SKIP_REVIEW:-0}"
SKIP_VERIFY="${SKIP_VERIFY:-0}"

# Phase timeouts (in seconds) - generous defaults to allow completion
TIMEOUT_TRIAGE="${TIMEOUT_TRIAGE:-120}"
TIMEOUT_PLAN="${TIMEOUT_PLAN:-300}"
TIMEOUT_IMPLEMENT="${TIMEOUT_IMPLEMENT:-1800}"
TIMEOUT_TEST="${TIMEOUT_TEST:-600}"
TIMEOUT_DOCS="${TIMEOUT_DOCS:-300}"
TIMEOUT_REVIEW="${TIMEOUT_REVIEW:-600}"   # Increased from 300 - complex tasks need more time
TIMEOUT_VERIFY="${TIMEOUT_VERIFY:-180}"   # Increased from 120 - includes committing

# Phase definitions: name|prompt_file|timeout|skip_var
PHASES=(
  "TRIAGE|1-triage.md|$TIMEOUT_TRIAGE|$SKIP_TRIAGE"
  "PLAN|2-plan.md|$TIMEOUT_PLAN|$SKIP_PLAN"
  "IMPLEMENT|3-implement.md|$TIMEOUT_IMPLEMENT|$SKIP_IMPLEMENT"
  "TEST|4-test.md|$TIMEOUT_TEST|$SKIP_TEST"
  "DOCS|5-docs.md|$TIMEOUT_DOCS|$SKIP_DOCS"
  "REVIEW|6-review.md|$TIMEOUT_REVIEW|$SKIP_REVIEW"
  "VERIFY|7-verify.md|$TIMEOUT_VERIFY|$SKIP_VERIFY"
)

# Model state (for fallback)
CURRENT_MODEL="$CLAUDE_MODEL"
MODEL_FALLBACK_TRIGGERED=0

# Generate unique agent ID with nicer default (atomic to prevent race conditions)
if [ -z "${AGENT_NAME:-}" ]; then
  # Ensure locks directory exists
  mkdir -p "$LOCKS_DIR" 2>/dev/null || true

  # Auto-generate worker name using atomic mkdir to prevent race conditions
  # When two agents start simultaneously, mkdir will fail for one of them
  WORKER_NUM=1
  while true; do
    WORKER_LOCK_DIR="$LOCKS_DIR/.worker-${WORKER_NUM}.active"
    # Use mkdir for atomic lock acquisition (fails if already exists)
    if mkdir "$WORKER_LOCK_DIR" 2>/dev/null; then
      # Successfully claimed this worker number
      echo "$$" > "$WORKER_LOCK_DIR/pid"
      break
    fi
    # Check if the existing lock is from a dead process
    if [ -f "$WORKER_LOCK_DIR/pid" ]; then
      OLD_PID=$(cat "$WORKER_LOCK_DIR/pid" 2>/dev/null || echo "0")
      if [ "$OLD_PID" != "0" ] && ! kill -0 "$OLD_PID" 2>/dev/null; then
        # Process is dead, reclaim this number
        rm -rf "$WORKER_LOCK_DIR" 2>/dev/null || true
        if mkdir "$WORKER_LOCK_DIR" 2>/dev/null; then
          echo "$$" > "$WORKER_LOCK_DIR/pid"
          break
        fi
      fi
    fi
    ((WORKER_NUM++))
    # Safety limit to prevent infinite loop
    if [ "$WORKER_NUM" -gt 100 ]; then
      echo "ERROR: Could not find available worker number (max 100)" >&2
      exit 1
    fi
  done
  AGENT_NAME="worker-${WORKER_NUM}"
fi
AGENT_ID="${AGENT_NAME}"

# Track locks held by this agent
HELD_LOCKS=()

# Track if this is an interrupt (Ctrl+C) vs normal exit
INTERRUPTED=0

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
CYAN='\033[0;36m'
MAGENTA='\033[0;35m'
BOLD='\033[1m'
NC='\033[0m'

# ============================================================================
# Logging
# ============================================================================

RUN_TIMESTAMP=$(date '+%Y%m%d-%H%M%S')
RUN_LOG_DIR="$LOGS_DIR/$RUN_TIMESTAMP-$AGENT_ID"

log_info() {
  echo -e "${BLUE}[$AGENT_ID]${NC} $1"
}

log_success() {
  echo -e "${GREEN}[$AGENT_ID OK]${NC} $1"
}

log_warn() {
  echo -e "${YELLOW}[$AGENT_ID WARN]${NC} $1"
}

log_error() {
  echo -e "${RED}[$AGENT_ID ERROR]${NC} $1"
}

log_step() {
  echo -e "${CYAN}[$AGENT_ID STEP]${NC} $1"
}

log_heal() {
  echo -e "${MAGENTA}[$AGENT_ID HEAL]${NC} $1"
}

log_lock() {
  echo -e "${YELLOW}[$AGENT_ID LOCK]${NC} $1"
}

log_model() {
  echo -e "${MAGENTA}[$AGENT_ID MODEL]${NC} $1"
}

log_phase() {
  echo -e "${BOLD}${CYAN}[$AGENT_ID PHASE]${NC} $1"
}

log_header() {
  echo ""
  echo -e "${BOLD}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
  echo -e "${BOLD} $1${NC}"
  echo -e "${BOLD} Agent: $AGENT_ID${NC}"
  echo -e "${BOLD}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
}

# ============================================================================
# Progress Filter (for AGENT_PROGRESS mode)
# ============================================================================

# Filter stream-json output to show one-line progress updates
progress_filter() {
  local phase_name="$1"
  local last_tool=""
  local line_count=0
  local start_time
  start_time=$(date +%s)

  # Show a status update (appends to log, no line clearing)
  show_status() {
    local elapsed=$(( $(date +%s) - start_time ))
    local mins=$(( elapsed / 60 ))
    local secs=$(( elapsed % 60 ))
    printf "${CYAN}[%s]${NC} ${BOLD}%s${NC} %02d:%02d â”‚ %s\n" "$AGENT_ID" "$phase_name" "$mins" "$secs" "$1"
  }

  while IFS= read -r line; do
    ((line_count++))

    # Try to parse JSON and extract meaningful info
    if command -v jq &>/dev/null; then
      local msg_type tool_name content
      msg_type=$(echo "$line" | jq -r '.type // empty' 2>/dev/null)

      case "$msg_type" in
        "assistant")
          # Assistant is thinking/responding
          content=$(echo "$line" | jq -r '.message.content[0].text // empty' 2>/dev/null | head -c 160)
          if [ -n "$content" ]; then
            show_status "ðŸ’­ ${content}..."
          fi
          ;;
        "content_block_start")
          local block_type
          block_type=$(echo "$line" | jq -r '.content_block.type // empty' 2>/dev/null)
          if [ "$block_type" = "tool_use" ]; then
            tool_name=$(echo "$line" | jq -r '.content_block.name // empty' 2>/dev/null)
            if [ -n "$tool_name" ] && [ "$tool_name" != "$last_tool" ]; then
              last_tool="$tool_name"
              show_status "ðŸ”§ $tool_name"
            fi
          fi
          ;;
        "result")
          local subtype cost_usd
          subtype=$(echo "$line" | jq -r '.subtype // empty' 2>/dev/null)
          cost_usd=$(echo "$line" | jq -r '.cost_usd // empty' 2>/dev/null)
          if [ "$subtype" = "success" ]; then
            show_status "âœ“ Done"
          elif [ -n "$cost_usd" ]; then
            show_status "ðŸ’° \$$cost_usd"
          fi
          ;;
        *)
          # For other types, just show activity indicator
          if [ $((line_count % 10)) -eq 0 ]; then
            show_status "â‹¯ working"
          fi
          ;;
      esac
    else
      # No jq available - simpler parsing
      if echo "$line" | grep -q '"tool_use"'; then
        local tool
        tool=$(echo "$line" | grep -oE '"name":"[^"]+"' | head -1 | cut -d'"' -f4)
        if [ -n "$tool" ] && [ "$tool" != "$last_tool" ]; then
          last_tool="$tool"
          show_status "ðŸ”§ $tool"
        fi
      elif echo "$line" | grep -q '"result"'; then
        show_status "âœ“ Done"
      elif [ $((line_count % 10)) -eq 0 ]; then
        show_status "â‹¯ working"
      fi
    fi
  done
}

# ============================================================================
# Lock Management (Parallel Agent Support)
# ============================================================================

init_locks() {
  mkdir -p "$LOCKS_DIR"
}

get_task_id_from_file() {
  local file="$1"
  basename "$file" .md
}

get_lock_file() {
  local task_id="$1"
  echo "$LOCKS_DIR/${task_id}.lock"
}

is_lock_stale() {
  local lock_file="$1"

  if [ ! -f "$lock_file" ]; then
    return 0  # No lock = stale (available)
  fi

  # Read lock info (strip quotes from values)
  local locked_at pid
  locked_at=$(grep "^LOCKED_AT=" "$lock_file" 2>/dev/null | cut -d= -f2 | tr -d '"' || echo "0")
  pid=$(grep "^PID=" "$lock_file" 2>/dev/null | cut -d= -f2 | tr -d '"' || echo "0")

  # Check if PID is still running
  if [ -n "$pid" ] && [ "$pid" != "0" ]; then
    if ! kill -0 "$pid" 2>/dev/null; then
      log_heal "Lock PID $pid is not running - lock is stale"
      return 0  # Process not running = stale
    fi
  fi

  # Check if lock is too old
  local now locked_timestamp age
  now=$(date +%s)
  locked_timestamp=$(date -j -f "%Y-%m-%d %H:%M:%S" "$locked_at" +%s 2>/dev/null || date -d "$locked_at" +%s 2>/dev/null || echo "0")

  if [ "$locked_timestamp" != "0" ]; then
    age=$((now - locked_timestamp))
    if [ "$age" -gt "$AGENT_LOCK_TIMEOUT" ]; then
      log_heal "Lock is ${age}s old (> ${AGENT_LOCK_TIMEOUT}s) - lock is stale"
      return 0  # Too old = stale
    fi
  fi

  return 1  # Lock is valid
}

is_task_locked() {
  local task_id="$1"
  local lock_file
  lock_file=$(get_lock_file "$task_id")

  if [ ! -f "$lock_file" ]; then
    return 1  # Not locked
  fi

  # Check if locked by us (strip quotes from value)
  local lock_agent
  lock_agent=$(grep "^AGENT_ID=" "$lock_file" 2>/dev/null | cut -d= -f2 | tr -d '"' || echo "")

  if [ "$lock_agent" = "$AGENT_ID" ]; then
    return 1  # Locked by us = available to us
  fi

  # Check if stale
  if is_lock_stale "$lock_file"; then
    log_heal "Removing stale lock for $task_id"
    rm -f "$lock_file"
    return 1  # Was stale, now available
  fi

  return 0  # Locked by another agent
}

acquire_lock() {
  local task_id="$1"
  local lock_file
  lock_file=$(get_lock_file "$task_id")

  # Atomic lock acquisition using mkdir (atomic on most filesystems)
  local lock_dir="${lock_file}.acquiring"

  if ! mkdir "$lock_dir" 2>/dev/null; then
    # Another agent is acquiring
    sleep 0.5
    if [ -d "$lock_dir" ]; then
      log_warn "Lock acquisition in progress by another agent for $task_id"
      return 1
    fi
  fi

  # Check again if locked (race condition protection)
  if [ -f "$lock_file" ]; then
    local lock_agent
    lock_agent=$(grep "^AGENT_ID=" "$lock_file" 2>/dev/null | cut -d= -f2 | tr -d '"' || echo "")

    if [ "$lock_agent" != "$AGENT_ID" ] && ! is_lock_stale "$lock_file"; then
      rmdir "$lock_dir" 2>/dev/null || true
      return 1  # Already locked by another
    fi
  fi

  # Write lock file
  cat > "$lock_file" << EOF
AGENT_ID="$AGENT_ID"
LOCKED_AT="$(date '+%Y-%m-%d %H:%M:%S')"
PID="$$"
TASK_ID="$task_id"
EOF

  rmdir "$lock_dir" 2>/dev/null || true

  # Track this lock
  HELD_LOCKS+=("$task_id")
  log_lock "Acquired lock for $task_id"

  return 0
}

release_lock() {
  local task_id="$1"
  local lock_file
  lock_file=$(get_lock_file "$task_id")

  if [ -f "$lock_file" ]; then
    local lock_agent
    lock_agent=$(grep "^AGENT_ID=" "$lock_file" 2>/dev/null | cut -d= -f2 | tr -d '"' || echo "")

    if [ "$lock_agent" = "$AGENT_ID" ]; then
      rm -f "$lock_file"
      log_lock "Released lock for $task_id"

      # Remove from held locks
      local new_held=()
      for held in "${HELD_LOCKS[@]}"; do
        if [ "$held" != "$task_id" ]; then
          new_held+=("$held")
        fi
      done
      HELD_LOCKS=("${new_held[@]+"${new_held[@]}"}")
    fi
  fi
}

release_all_locks() {
  log_lock "Releasing all held locks..."
  for task_id in "${HELD_LOCKS[@]+"${HELD_LOCKS[@]}"}"; do
    release_lock "$task_id"
  done
  HELD_LOCKS=()
}

# ============================================================================
# Task File Git Operations
# ============================================================================

commit_task_files() {
  local message="$1"
  local task_id="${2:-}"

  # Stage all task-related changes
  git add "$TASKS_DIR" TASKBOARD.md 2>/dev/null || true

  # Check if there's anything to commit
  if git diff --cached --quiet 2>/dev/null; then
    return 0  # Nothing to commit
  fi

  # Commit with appropriate message
  if [ -n "$task_id" ]; then
    git commit -m "$message [$task_id]" --no-verify 2>/dev/null || true
  else
    git commit -m "$message" --no-verify 2>/dev/null || true
  fi

  log_info "Committed task file changes: $message"
}

# ============================================================================
# Task Assignment (Update task file metadata)
# ============================================================================

assign_task() {
  local task_file="$1"
  local timestamp
  timestamp=$(date '+%Y-%m-%d %H:%M')

  # Update Assigned To and Assigned At in task file
  if [ -f "$task_file" ]; then
    # Use sed to update the metadata table
    if grep -q "| Assigned To |" "$task_file"; then
      sed -i.bak "s/| Assigned To | .*/| Assigned To | \`$AGENT_ID\` |/" "$task_file"
      sed -i.bak "s/| Assigned At | .*/| Assigned At | \`$timestamp\` |/" "$task_file"
      rm -f "${task_file}.bak"
    fi
    log_info "Assigned task to $AGENT_ID"
  fi
}

unassign_task() {
  local task_file="$1"

  # Clear Assigned To and Assigned At in task file
  if [ -f "$task_file" ]; then
    if grep -q "| Assigned To |" "$task_file"; then
      sed -i.bak "s/| Assigned To | .*/| Assigned To | |/" "$task_file"
      sed -i.bak "s/| Assigned At | .*/| Assigned At | |/" "$task_file"
      rm -f "${task_file}.bak"
    fi
    log_info "Unassigned task"
  fi
}

refresh_assignment() {
  local task_file="$1"
  local timestamp
  timestamp=$(date '+%Y-%m-%d %H:%M')

  # Update only Assigned At to refresh the heartbeat
  if [ -f "$task_file" ]; then
    if grep -q "| Assigned At |" "$task_file"; then
      sed -i.bak "s/| Assigned At | .*/| Assigned At | \`$timestamp\` |/" "$task_file"
      rm -f "${task_file}.bak"
    fi
    log_info "Refreshed assignment timestamp"
  fi
}

# ============================================================================
# Heartbeat (Refresh assignment to prevent stale detection)
# ============================================================================

HEARTBEAT_PID=""
CURRENT_TASK_FILE=""

start_heartbeat() {
  local task_file="$1"
  CURRENT_TASK_FILE="$task_file"

  # Stop any existing heartbeat
  stop_heartbeat

  # Start background heartbeat process
  (
    while true; do
      sleep "$AGENT_HEARTBEAT"
      if [ -f "$CURRENT_TASK_FILE" ]; then
        refresh_assignment "$CURRENT_TASK_FILE"
        # Also refresh the lock file
        local task_id
        task_id=$(get_task_id_from_file "$CURRENT_TASK_FILE")
        local lock_file
        lock_file=$(get_lock_file "$task_id")
        if [ -f "$lock_file" ]; then
          cat > "$lock_file" << EOF
AGENT_ID="$AGENT_ID"
LOCKED_AT="$(date '+%Y-%m-%d %H:%M:%S')"
PID="$$"
TASK_ID="$task_id"
EOF
        fi
      fi
    done
  ) &
  HEARTBEAT_PID=$!
  log_info "Started heartbeat (PID: $HEARTBEAT_PID, interval: ${AGENT_HEARTBEAT}s)"
}

stop_heartbeat() {
  if [ -n "$HEARTBEAT_PID" ] && kill -0 "$HEARTBEAT_PID" 2>/dev/null; then
    kill "$HEARTBEAT_PID" 2>/dev/null || true
    wait "$HEARTBEAT_PID" 2>/dev/null || true
    log_info "Stopped heartbeat"
  fi
  HEARTBEAT_PID=""
}

# ============================================================================
# Model Fallback (opus -> sonnet on rate limits)
# ============================================================================

fallback_to_sonnet() {
  if [ "$AGENT_NO_FALLBACK" = "1" ]; then
    log_warn "Model fallback disabled (AGENT_NO_FALLBACK=1)"
    return 1
  fi

  if [ "$CURRENT_MODEL" = "sonnet" ]; then
    log_warn "Already using sonnet, cannot fall back further"
    return 1
  fi

  log_model "Falling back from $CURRENT_MODEL to sonnet due to rate limits"
  CURRENT_MODEL="sonnet"
  MODEL_FALLBACK_TRIGGERED=1
  return 0
}

reset_model() {
  if [ "$MODEL_FALLBACK_TRIGGERED" = "1" ]; then
    log_model "Resetting model back to $CLAUDE_MODEL after successful run"
    CURRENT_MODEL="$CLAUDE_MODEL"
    MODEL_FALLBACK_TRIGGERED=0
  fi
}

# ============================================================================
# Phase Execution (Modular Workflow)
# ============================================================================

build_phase_prompt() {
  local prompt_file="$1"
  local task_id="$2"
  local task_file="$3"
  local timestamp
  timestamp=$(date '+%Y-%m-%d %H:%M')

  # Read the prompt template
  local template
  if [ -f "$PROMPTS_DIR/$prompt_file" ]; then
    template=$(cat "$PROMPTS_DIR/$prompt_file")
  else
    log_error "Prompt file not found: $PROMPTS_DIR/$prompt_file"
    return 1
  fi

  # Get recent commits for REVIEW phase
  local recent_commits=""
  if [[ "$prompt_file" == *"review"* ]]; then
    recent_commits=$(git log --oneline -10 --grep="$task_id" 2>/dev/null || echo "(no commits yet)")
  fi

  # Substitute template variables
  local prompt="$template"
  prompt="${prompt//\{\{TASK_ID\}\}/$task_id}"
  prompt="${prompt//\{\{TASK_FILE\}\}/$task_file}"
  prompt="${prompt//\{\{TIMESTAMP\}\}/$timestamp}"
  prompt="${prompt//\{\{RECENT_COMMITS\}\}/$recent_commits}"
  prompt="${prompt//\{\{AGENT_ID\}\}/$AGENT_ID}"

  echo "$prompt"
}

run_phase_once() {
  local phase_name="$1"
  local prompt_file="$2"
  local timeout="$3"
  local task_id="$4"
  local task_file="$5"
  local attempt="$6"
  local phase_name_lower
  phase_name_lower=$(echo "$phase_name" | tr '[:upper:]' '[:lower:]')
  local phase_log="$RUN_LOG_DIR/phase-${phase_name_lower}-$task_id-attempt${attempt}.log"

  log_phase "Starting $phase_name phase (attempt $attempt)"
  echo "  Timeout: ${timeout}s"
  echo "  Log: $phase_log"

  # Build the prompt from template
  local prompt build_result=0
  prompt=$(build_phase_prompt "$prompt_file" "$task_id" "$task_file") || build_result=$?
  if [ "$build_result" -ne 0 ]; then
    log_error "Failed to build prompt for $phase_name (prompt file: $PROMPTS_DIR/$prompt_file)"
    return 1
  fi

  # Build Claude CLI arguments
  local claude_args=(
    "--dangerously-skip-permissions"
    "--permission-mode" "bypassPermissions"
    "--model" "$CURRENT_MODEL"
  )

  # Output mode: streaming (default), progress (filtered), or quiet
  local output_mode="stream"
  if [ "$AGENT_QUIET" = "1" ]; then
    output_mode="quiet"
    claude_args+=("-p")
  elif [ "$AGENT_PROGRESS" = "1" ]; then
    output_mode="progress"
    # stream-json requires --verbose
    claude_args+=("--output-format" "stream-json" "--verbose")
  else
    # stream-json requires --verbose
    claude_args+=("--output-format" "stream-json" "--verbose")
  fi

  local exit_code=0

  echo ""
  echo -e "${CYAN}â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”${NC}"
  echo -e "${CYAN}â”‚${NC} ${BOLD}PHASE: $phase_name (attempt $attempt)${NC}"
  echo -e "${CYAN}â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜${NC}"
  echo ""

  # Execute with timeout - different output handling based on mode
  if [ "$output_mode" = "progress" ]; then
    # Progress mode: filter output to show one-line updates
    if command -v gtimeout &> /dev/null; then
      gtimeout "${timeout}s" claude "${claude_args[@]}" "$prompt" 2>&1 | tee "$phase_log" | progress_filter "$phase_name" || exit_code=$?
    elif command -v timeout &> /dev/null; then
      timeout "${timeout}s" claude "${claude_args[@]}" "$prompt" 2>&1 | tee "$phase_log" | progress_filter "$phase_name" || exit_code=$?
    else
      claude "${claude_args[@]}" "$prompt" 2>&1 | tee "$phase_log" | progress_filter "$phase_name" || exit_code=$?
    fi
  else
    # Full stream or quiet mode
    if command -v gtimeout &> /dev/null; then
      gtimeout "${timeout}s" claude "${claude_args[@]}" "$prompt" 2>&1 | tee "$phase_log" || exit_code=$?
    elif command -v timeout &> /dev/null; then
      timeout "${timeout}s" claude "${claude_args[@]}" "$prompt" 2>&1 | tee "$phase_log" || exit_code=$?
    else
      claude "${claude_args[@]}" "$prompt" 2>&1 | tee "$phase_log" || exit_code=$?
    fi
  fi

  echo ""
  echo -e "${CYAN}â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜${NC}"
  echo ""

  # Handle exit codes
  case $exit_code in
    0)
      log_phase "$phase_name completed successfully"
      return 0
      ;;
    124)
      log_error "$phase_name timed out after ${timeout}s"
      # Return special code for timeout
      return 124
      ;;
    *)
      # Check for rate limits
      if grep -qiE "rate.?limit|overloaded|429|502|503|504|capacity|quota" "$phase_log" 2>/dev/null; then
        log_heal "Rate limit detected in $phase_name"
        if fallback_to_sonnet; then
          log_heal "Will retry $phase_name with sonnet"
        fi
        return 2  # Retryable error
      fi
      log_error "$phase_name failed with exit code $exit_code"
      return 1
      ;;
  esac
}

run_phase() {
  local phase_name="$1"
  local prompt_file="$2"
  local timeout="$3"
  local skip="$4"
  local task_id="$5"
  local task_file="$6"

  # Check if phase should be skipped
  if [ "$skip" = "1" ]; then
    log_phase "Skipping $phase_name (disabled)"
    return 0
  fi

  # Retry loop for individual phase
  local attempt=1
  local max_attempts="$AGENT_MAX_RETRIES"

  while [ "$attempt" -le "$max_attempts" ]; do
    local result=0
    run_phase_once "$phase_name" "$prompt_file" "$timeout" "$task_id" "$task_file" "$attempt" || result=$?

    case $result in
      0)
        return 0  # Success
        ;;
      124)
        # Timeout - don't retry, timeouts mean we need more time
        log_error "$phase_name timed out - consider increasing TIMEOUT_${phase_name}"
        return 1
        ;;
      2)
        # Rate limit - retry with backoff
        if [ "$attempt" -lt "$max_attempts" ]; then
          local backoff=$((AGENT_RETRY_DELAY * attempt))
          log_heal "Retrying $phase_name in ${backoff}s (attempt $((attempt + 1))/$max_attempts)"
          sleep "$backoff"
        fi
        ;;
      *)
        # Other error - retry
        if [ "$attempt" -lt "$max_attempts" ]; then
          local backoff=$((AGENT_RETRY_DELAY * attempt))
          log_heal "Retrying $phase_name in ${backoff}s (attempt $((attempt + 1))/$max_attempts)"
          sleep "$backoff"
        fi
        ;;
    esac

    ((attempt++))
  done

  log_error "$phase_name failed after $max_attempts attempts - check logs: $RUN_LOG_DIR/phase-*"
  return 1
}

run_all_phases() {
  local task_id="$1"
  local task_file="$2"

  log_info "Running ${#PHASES[@]} phases for task: $task_id"

  for phase_def in "${PHASES[@]}"; do
    IFS='|' read -r name prompt_file timeout skip <<< "$phase_def"

    if ! run_phase "$name" "$prompt_file" "$timeout" "$skip" "$task_id" "$task_file"; then
      log_error "Phase $name failed - stopping task execution"
      return 1
    fi

    # Small pause between phases
    sleep 1
  done

  log_success "All phases completed for task: $task_id"
  return 0
}

# ============================================================================
# State Management (Self-Healing)
# ============================================================================

init_state() {
  mkdir -p "$STATE_DIR"
  mkdir -p "$RUN_LOG_DIR"
  init_locks
}

save_session() {
  local session_id="$1"
  local iteration="$2"
  local status="$3"
  local session_file="$STATE_DIR/session-$AGENT_ID"

  cat > "$session_file" << EOF
SESSION_ID="$session_id"
AGENT_ID="$AGENT_ID"
ITERATION="$iteration"
STATUS="$status"
TIMESTAMP="$(date '+%Y-%m-%d %H:%M:%S')"
NUM_TASKS="$NUM_TASKS"
MODEL="$CLAUDE_MODEL"
LOG_DIR="$RUN_LOG_DIR"
EOF
  log_info "Session state saved: $session_id (iteration $iteration)"
}

load_session() {
  local session_file="$STATE_DIR/session-$AGENT_ID"

  if [ -f "$session_file" ] && [ "$AGENT_NO_RESUME" != "1" ]; then
    # shellcheck source=/dev/null
    source "$session_file"
    if [ -n "${SESSION_ID:-}" ] && [ "${STATUS:-}" = "running" ]; then
      log_heal "Found interrupted session: $SESSION_ID"
      log_heal "Last iteration: ${ITERATION:-1}, Status: $STATUS"
      return 0
    fi
  fi
  return 1
}

clear_session() {
  local session_file="$STATE_DIR/session-$AGENT_ID"
  rm -f "$session_file"
}

update_health() {
  local status="$1"
  local message="$2"
  local health_file="$STATE_DIR/health-$AGENT_ID"

  cat > "$health_file" << EOF
STATUS="$status"
MESSAGE="$message"
AGENT_ID="$AGENT_ID"
LAST_CHECK="$(date '+%Y-%m-%d %H:%M:%S')"
CONSECUTIVE_FAILURES="${CONSECUTIVE_FAILURES:-0}"
EOF
}

get_consecutive_failures() {
  local health_file="$STATE_DIR/health-$AGENT_ID"
  if [ -f "$health_file" ]; then
    grep "^CONSECUTIVE_FAILURES=" "$health_file" 2>/dev/null | cut -d= -f2 | tr -d '"' || echo "0"
  else
    echo "0"
  fi
}

# ============================================================================
# Health Checks
# ============================================================================

health_check() {
  log_step "Running health checks..."

  local issues=0

  # Check Claude CLI
  if ! command -v claude &> /dev/null; then
    log_error "Claude CLI not found"
    ((issues++))
  else
    log_success "Claude CLI available"
  fi

  # Check timeout command (optional but recommended for phase timeouts)
  if command -v gtimeout &> /dev/null; then
    log_success "Timeout available (gtimeout)"
  elif command -v timeout &> /dev/null; then
    log_success "Timeout available (timeout)"
  else
    log_warn "No timeout command found (gtimeout/timeout) - phases will run without time limits"
    log_warn "Install coreutils for timeout support: brew install coreutils (macOS)"
  fi

  # Check CLAUDE.md exists
  if [ ! -f "$PROJECT_DIR/CLAUDE.md" ]; then
    log_error "CLAUDE.md not found"
    ((issues++))
  else
    log_success "CLAUDE.md exists"
  fi

  # Check task directories (quote "done" to avoid shellcheck warning about keyword)
  for dir in todo doing "done" _templates; do
    if [ ! -d "$TASKS_DIR/$dir" ]; then
      log_warn "Creating missing directory: $TASKS_DIR/$dir"
      mkdir -p "$TASKS_DIR/$dir"
    fi
  done
  log_success "Task directories ready"

  # Check locks directory
  if [ ! -d "$LOCKS_DIR" ]; then
    mkdir -p "$LOCKS_DIR"
  fi
  log_success "Locks directory ready"

  # Check disk space (warn if < 1GB)
  local available_kb
  available_kb=$(df -k "$PROJECT_DIR" | awk 'NR==2 {print $4}')
  if [ "$available_kb" -lt 1048576 ]; then
    log_warn "Low disk space: $((available_kb / 1024))MB available"
  else
    log_success "Disk space OK: $((available_kb / 1024))MB available"
  fi

  # Show active agents
  local active_locks
  active_locks=$(find "$LOCKS_DIR" -name "*.lock" 2>/dev/null | wc -l | tr -d ' ')
  if [ "$active_locks" -gt 0 ]; then
    log_info "Active task locks: $active_locks"
  fi

  if [ "$issues" -gt 0 ]; then
    update_health "unhealthy" "$issues issues found"
    return 1
  fi

  update_health "healthy" "All checks passed"
  return 0
}

# ============================================================================
# Validation
# ============================================================================

validate_environment() {
  log_step "Validating environment..."

  # Validate NUM_TASKS is a number
  if ! [[ "$NUM_TASKS" =~ ^[0-9]+$ ]]; then
    log_error "Invalid number of tasks: $NUM_TASKS"
    echo "Usage: $0 [number_of_tasks]"
    exit 1
  fi

  if [ "$NUM_TASKS" -lt 1 ] || [ "$NUM_TASKS" -gt 50 ]; then
    log_error "Number of tasks must be between 1 and 50"
    exit 1
  fi

  log_success "Environment validated"
}

# ============================================================================
# Task Management
# ============================================================================

count_tasks() {
  local state="$1"
  find "$TASKS_DIR/$state" -maxdepth 1 -name "*.md" 2>/dev/null | wc -l | tr -d ' '
}

count_locked_tasks() {
  find "$LOCKS_DIR" -maxdepth 1 -name "*.lock" 2>/dev/null | wc -l | tr -d ' '
}

get_doing_task_for_agent() {
  # Look for a task in doing/ that we have locked
  for file in "$TASKS_DIR/doing"/*.md; do
    [ -f "$file" ] || continue
    local task_id
    task_id=$(get_task_id_from_file "$file")

    local lock_file
    lock_file=$(get_lock_file "$task_id")

    if [ -f "$lock_file" ]; then
      local lock_agent
      lock_agent=$(grep "^AGENT_ID=" "$lock_file" 2>/dev/null | cut -d= -f2 | tr -d '"' || echo "")
      if [ "$lock_agent" = "$AGENT_ID" ]; then
        echo "$file"
        return 0
      fi
    fi
  done

  return 1
}

get_next_available_task() {
  # First check doing/ for tasks we own
  local our_doing
  our_doing=$(get_doing_task_for_agent) || true
  if [ -n "$our_doing" ]; then
    echo "$our_doing"
    return 0
  fi

  # Then check todo/ for unassigned tasks (sorted by priority)
  for file in $(find "$TASKS_DIR/todo" -maxdepth 1 -name "*.md" 2>/dev/null | sort); do
    [ -f "$file" ] || continue
    local task_id
    task_id=$(get_task_id_from_file "$file")

    if ! is_task_locked "$task_id"; then
      echo "$file"
      return 0
    else
      log_info "Skipping $task_id (locked by another agent)"
    fi
  done

  return 1
}

show_task_summary() {
  log_info "Task Summary:"
  echo "  - Todo:    $(count_tasks todo)"
  echo "  - Doing:   $(count_tasks doing)"
  # shellcheck disable=SC1010
  echo "  - Done:    $(count_tasks "done")"
  echo "  - Locked:  $(count_locked_tasks)"
}

# ============================================================================
# Retry Logic with Exponential Backoff
# ============================================================================

calculate_backoff() {
  local attempt="$1"
  local base_delay="$AGENT_RETRY_DELAY"
  local max_delay=60

  # Exponential backoff: base * 2^(attempt-1), capped at max_delay
  local delay=$((base_delay * (2 ** (attempt - 1))))
  if [ "$delay" -gt "$max_delay" ]; then
    delay=$max_delay
  fi

  echo "$delay"
}

run_with_retry() {
  local iteration="$1"
  local max_retries="$AGENT_MAX_RETRIES"
  local attempt=1

  while [ "$attempt" -le "$max_retries" ]; do
    if [ "$attempt" -gt 1 ]; then
      local backoff
      backoff=$(calculate_backoff "$attempt")
      log_heal "Retry attempt $attempt/$max_retries (waiting ${backoff}s)..."
      sleep "$backoff"
    fi

    if run_agent_iteration "$iteration" "$attempt"; then
      CONSECUTIVE_FAILURES=0
      return 0
    fi

    ((attempt++))
  done

  log_error "All $max_retries retry attempts failed for iteration $iteration"
  log_info "Troubleshooting: check logs in $RUN_LOG_DIR, or increase AGENT_MAX_RETRIES"
  ((CONSECUTIVE_FAILURES++))

  # Circuit breaker: if too many consecutive failures, pause longer
  if [ "$CONSECUTIVE_FAILURES" -ge 3 ]; then
    log_heal "Circuit breaker triggered: $CONSECUTIVE_FAILURES consecutive failures"
    log_heal "Pausing for 30 seconds before continuing..."
    log_info "If persistent failures, check API rate limits or task complexity"
    sleep 30
  fi

  return 1
}

# ============================================================================
# Agent Execution
# ============================================================================

run_agent_iteration() {
  local iteration="$1"
  local attempt="${2:-1}"
  local session_id

  # Generate or reuse session ID
  session_id="$AGENT_ID-iter$iteration"

  log_header "Task $iteration of $NUM_TASKS (Attempt $attempt)"

  # Save state before running
  save_session "$session_id" "$iteration" "running"

  # Show current state
  show_task_summary

  # Find a task to work on
  local task_file
  task_file=$(get_next_available_task) || true

  if [ -z "$task_file" ]; then
    log_info "No available tasks (all locked or empty)"
    log_info "Agent will create one from MISSION.md or wait for tasks"
    # Let Claude handle creating a task
  else
    local task_id
    task_id=$(get_task_id_from_file "$task_file")

    # Check if already in doing/
    if [[ "$task_file" == *"/doing/"* ]]; then
      log_info "Resuming task: $task_id"
    else
      log_info "Picking up task: $task_id"

      # Acquire lock
      if ! acquire_lock "$task_id"; then
        log_warn "Failed to acquire lock for $task_id - another agent got it"
        # Try to find another task
        return 1
      fi

      # Move to doing/
      local new_path
      new_path="$TASKS_DIR/doing/$(basename "$task_file")"
      mv "$task_file" "$new_path"
      task_file="$new_path"

      # Update task metadata
      assign_task "$task_file"

      # Commit the task pickup
      commit_task_files "chore: Start task $task_id" "$task_id"
    fi
  fi

  if [ "$AGENT_DRY_RUN" = "1" ]; then
    log_warn "DRY RUN - would execute phases here"
    log_info "Phases: ${PHASES[*]}"
    save_session "$session_id" "$iteration" "dry-run"
    return 0
  fi

  # Ensure we have a task to work on
  if [ -z "${task_file:-}" ]; then
    log_error "No task file available for phase execution"
    save_session "$session_id" "$iteration" "no-task"
    return 1
  fi

  local task_id
  task_id=$(get_task_id_from_file "$task_file")

  # Start heartbeat for long-running tasks
  start_heartbeat "$task_file"

  log_step "Running modular phase-based execution..."
  echo "  Task: $task_id"
  echo "  Model: $CURRENT_MODEL"
  echo "  Phases: TRIAGE â†’ PLAN â†’ IMPLEMENT â†’ TEST â†’ DOCS â†’ REVIEW â†’ VERIFY"
  if [ "$AGENT_QUIET" = "1" ]; then
    echo "  Output: quiet"
  elif [ "$AGENT_PROGRESS" != "1" ]; then
    echo "  Output: full stream"
  else
    echo "  Output: progress"
  fi
  echo ""

  # Execute all phases
  local exit_code=0
  if ! run_all_phases "$task_id" "$task_file"; then
    exit_code=1
  fi

  # Stop heartbeat
  stop_heartbeat

  # Handle result
  if [ "$exit_code" -eq 0 ]; then
    log_success "Task iteration completed successfully"
    save_session "$session_id" "$iteration" "completed"

    # Reset model on success
    reset_model

    # Check if task was completed (moved to done/)
    local done_file
    done_file="$TASKS_DIR/done/$(basename "$task_file")"
    if [ -f "$done_file" ]; then
      release_lock "$task_id"
      unassign_task "$done_file"
      # Final commit to ensure task completion is recorded
      commit_task_files "chore: Complete task $task_id" "$task_id"
    fi

    return 0
  else
    log_error "Task iteration failed"
    save_session "$session_id" "$iteration" "failed"
    return 1
  fi
}

# ============================================================================
# Cleanup
# ============================================================================

cleanup() {
  # Check if this is an interrupt (Ctrl+C / SIGTERM)
  if [ "$INTERRUPTED" = "1" ]; then
    log_info "Interrupted - preserving task state for resume..."

    # Stop heartbeat
    stop_heartbeat

    # Remove active marker (for auto-numbering) - now a directory
    rm -rf "$LOCKS_DIR/.${AGENT_ID}.active" 2>/dev/null || true

    # Keep the lock and assignment so the task can be resumed
    # Don't call release_all_locks or unassign_task

    # Generate taskboard
    if [ -x "$SCRIPTS_DIR/taskboard.sh" ]; then
      "$SCRIPTS_DIR/taskboard.sh" 2>/dev/null || true
    fi

    log_info "Task preserved in doing/ - run './bin/agent' to resume"
  else
    # Normal exit - full cleanup
    log_info "Cleaning up..."

    # Stop heartbeat
    stop_heartbeat

    # Release all locks held by this agent
    release_all_locks

    # Remove active marker (for auto-numbering) - now a directory
    rm -rf "$LOCKS_DIR/.${AGENT_ID}.active" 2>/dev/null || true

    # Unassign any tasks we were working on
    for file in "$TASKS_DIR/doing"/*.md; do
      [ -f "$file" ] || continue
      if grep -q "$AGENT_ID" "$file" 2>/dev/null; then
        unassign_task "$file"
      fi
    done

    # Generate taskboard
    if [ -x "$SCRIPTS_DIR/taskboard.sh" ]; then
      "$SCRIPTS_DIR/taskboard.sh" 2>/dev/null || true
    fi
  fi
}

handle_interrupt() {
  echo ""  # Newline after ^C
  INTERRUPTED=1
  exit 130  # Standard exit code for Ctrl+C (128 + signal 2)
}

trap handle_interrupt INT TERM
trap cleanup EXIT

# ============================================================================
# Main
# ============================================================================

main() {
  log_header "Claude Agent Runner (Phase-Based)"
  echo ""
  echo "  Agent ID: $AGENT_ID"
  echo "  Tasks to run: $NUM_TASKS"
  echo "  Model: $CLAUDE_MODEL (fallback: sonnet)"
  echo "  Max retries: $AGENT_MAX_RETRIES per phase"
  echo "  Lock timeout: ${AGENT_LOCK_TIMEOUT}s ($(( AGENT_LOCK_TIMEOUT / 3600 ))h)"
  echo "  Heartbeat: ${AGENT_HEARTBEAT}s ($(( AGENT_HEARTBEAT / 60 ))min)"
  if [ "$AGENT_QUIET" = "1" ]; then
    echo "  Output: quiet (no streaming)"
  elif [ "$AGENT_PROGRESS" != "1" ]; then
    echo "  Output: full stream (verbose)"
  else
    echo "  Output: progress (one-line updates)"
  fi
  echo ""
  echo "  Phases:"
  echo "    1. TRIAGE    ${TIMEOUT_TRIAGE}s  $([ "$SKIP_TRIAGE" = "1" ] && echo "[SKIP]" || echo "")"
  echo "    2. PLAN      ${TIMEOUT_PLAN}s  $([ "$SKIP_PLAN" = "1" ] && echo "[SKIP]" || echo "")"
  echo "    3. IMPLEMENT ${TIMEOUT_IMPLEMENT}s  $([ "$SKIP_IMPLEMENT" = "1" ] && echo "[SKIP]" || echo "")"
  echo "    4. TEST      ${TIMEOUT_TEST}s  $([ "$SKIP_TEST" = "1" ] && echo "[SKIP]" || echo "")"
  echo "    5. DOCS      ${TIMEOUT_DOCS}s  $([ "$SKIP_DOCS" = "1" ] && echo "[SKIP]" || echo "")"
  echo "    6. REVIEW    ${TIMEOUT_REVIEW}s  $([ "$SKIP_REVIEW" = "1" ] && echo "[SKIP]" || echo "")"
  echo "    7. VERIFY    ${TIMEOUT_VERIFY}s  $([ "$SKIP_VERIFY" = "1" ] && echo "[SKIP]" || echo "")"
  echo ""
  echo "  Log dir: $RUN_LOG_DIR"
  echo ""

  # Initialize state
  init_state

  # Run health checks
  if ! health_check; then
    log_error "Health check failed - aborting"
    exit 1
  fi

  # Check for interrupted session to resume
  local start_iteration=1
  if load_session; then
    log_heal "Resuming from iteration ${ITERATION:-1}"
    start_iteration="${ITERATION:-1}"
    # Inherit the log directory from the interrupted session if available
    if [ -n "${LOG_DIR:-}" ] && [ -d "$LOG_DIR" ]; then
      RUN_LOG_DIR="$LOG_DIR"
      log_info "Resuming logs in: $RUN_LOG_DIR"
    fi
  fi

  # Validate environment
  validate_environment

  # Track results
  local completed=0
  local failed=0
  local skipped=0
  CONSECUTIVE_FAILURES=$(get_consecutive_failures)

  # Run agent for N iterations with retry
  for ((i=start_iteration; i<=NUM_TASKS; i++)); do
    if run_with_retry "$i"; then
      ((completed++))
    else
      # Check if we failed because no tasks available
      local available
      available=$(get_next_available_task) || true
      if [ -z "$available" ] && [ "$(count_tasks todo)" -eq 0 ]; then
        log_info "No more tasks available - stopping early"
        ((skipped++))
        break
      fi
      ((failed++))
      log_warn "Moving to next task after exhausting retries..."
    fi

    # Small pause between iterations (unless it's the last one)
    if [ "$i" -lt "$NUM_TASKS" ]; then
      sleep 2
    fi
  done

  # Clear session on successful completion
  if [ "$failed" -eq 0 ]; then
    clear_session
  fi

  # Final summary
  log_header "Run Complete"
  echo ""
  echo "  Agent: $AGENT_ID"
  echo "  Completed: $completed"
  echo "  Failed: $failed"
  echo "  Skipped: $skipped"
  echo "  Logs: $RUN_LOG_DIR"
  echo ""
  show_task_summary

  if [ "$failed" -gt 0 ]; then
    log_warn "Some tasks failed - run './bin/agent' again to retry"
    exit 1
  fi

  log_success "All tasks completed successfully!"
}

# ============================================================================
# Entry Point
# ============================================================================

# Change to repo root
cd "$PROJECT_DIR"

# Run main
main "$@"
